{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock_Query\n",
    "This script runs the output of the Query_List.ipynb (Query_List.csv) and returns 20 years of daily-time series data for each stock. Data is pulled from the Alpha Vantage API. Data is then to be used in analytica for research.\n",
    "\n",
    "Script PFD:\n",
    "\n",
    "1. FortuneList Sorting \n",
    "2. Ticker_Lookup(in FortuneList) \n",
    "3. Symbol_Corrections(in FortuneList) \n",
    "4. Stock_Query \n",
    "5. StockMarketCrash_Analytica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!Query Initiated!\n",
      "-----------------\n",
      "\n",
      "Record 1 out of 6 processed. ARNC : SUCCESS(5034 rows)\n",
      "Record 2 out of 6 processed. MSFT : SUCCESS(5034 rows)\n",
      "Record 3 out of 6 processed. KO : SUCCESS(5034 rows)\n",
      "Record 4 out of 6 processed. ODP : SUCCESS(5034 rows)\n",
      "Record 5 out of 6 processed. OMX : SUCCESS(1726 rows)\n",
      "Record 6 out of 6 processed. GE : SUCCESS(5034 rows)\n",
      "\n",
      "DONE\n",
      "------------------\n",
      "Query Summary\n",
      "Success: 6 \n",
      "Failed: 0\n",
      "Total: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "import time\n",
    "import pandas as pd\n",
    "from config import api_key_av\n",
    "import requests\n",
    "\n",
    "\n",
    "# reading in query_list for required tickers\n",
    "query_list = pd.read_csv('../Resources/Query_List.csv')\n",
    "query_list['ticker'].tolist()\n",
    "tickers = ['ARNC', 'MSFT', 'KO', 'ODP', 'OMX', 'GE']\n",
    "\n",
    "# terminal print out of script performance\n",
    "print(f'''\n",
    "!Query Initiated!\n",
    "-----------------\n",
    "''')\n",
    "\n",
    "\n",
    "# creating hard-coded values (for ease of future expansion)\n",
    "max_call = 5 #calls per minute allowed by Alpha Vantage\n",
    "wait_time = 60\n",
    "\n",
    "# creating loop counters & summary stat counters\n",
    "success = 0 #success API call counter\n",
    "failed = 0 #failed API call counter\n",
    "pull_time = 0 #future pull time variable\n",
    "counter = 0 #API call counter\n",
    "\n",
    "# creating master dataframe (to append to)\n",
    "master_df = pd.DataFrame(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker'])\n",
    "\n",
    "# primary loop for ticker call list to API\n",
    "for record, ticker in enumerate(tickers):\n",
    "    \n",
    "    # setting API call parameters (ticker)\n",
    "    params = {\n",
    "        'function' : 'TIME_SERIES_DAILY',\n",
    "        'symbol' : ticker,\n",
    "        'outputsize' : 'full',\n",
    "        'datatype' : 'json',\n",
    "        'apikey' : api_key_av\n",
    "    }\n",
    "    \n",
    "    # base API call URL\n",
    "    url = 'https://www.alphavantage.co/query?'\n",
    "    \n",
    "    # updating time to now\n",
    "    now = time.time()\n",
    "    \n",
    "    # API call wait function (limited to 5 calls per minute); is utilized after counter resets from 5 to 0\n",
    "    if counter == 0:\n",
    "        while now < pull_time:\n",
    "            now = time.time()\n",
    "    \n",
    "    # if statement verifying proper time and counter for being able to make a successful API call\n",
    "    if pull_time < now and counter < max_call:\n",
    "        \n",
    "        # trying API call and skipping if failed for any reason\n",
    "        try:\n",
    "            \n",
    "            # making API call and storing data into variable\n",
    "            response = requests.get(url, params).json()\n",
    "                                    \n",
    "            # THE MEAT AND POTATOS\n",
    "            # creating main ticker dataframe\n",
    "            ticker_df = pd.DataFrame(response['Time Series (Daily)']).transpose().reset_index()\n",
    "            \n",
    "            # renaming columns to better indicators\n",
    "            ticker_df = ticker_df.rename(columns={\n",
    "                'index':'Date',\n",
    "                '1. open':'Open',\n",
    "                '2. high':'High',\n",
    "                '3. low':'Low',\n",
    "                '4. close':'Close',\n",
    "                '5. volume':'Volume'\n",
    "            })\n",
    "            \n",
    "            # pulling ticker symbol for confirmation purposes from API\n",
    "            ticker_df['Ticker'] = response['Meta Data']['2. Symbol']\n",
    "            \n",
    "            \n",
    "            # appending items to master dataframe\n",
    "            master_df = master_df.append(ticker_df)\n",
    "            \n",
    "            row_count = ticker_df['Date'].count()\n",
    "            \n",
    "            print(f'Record {record + 1} out of {len(tickers)} processed. {ticker} : SUCCESS({row_count} rows)')\n",
    "            \n",
    "            success += 1\n",
    "            counter += 1\n",
    "            \n",
    "            # resetting counter to 0 to initiate next call limit & wait function\n",
    "            if counter == max_call:\n",
    "                pull_time = int(time.time()) + wait_time\n",
    "                counter = 0\n",
    "                \n",
    "        # handeling failed API calls\n",
    "        except:\n",
    "            print(f'Record {record + 1} out of {len(tickers)} processed. {ticker} : FAILED')\n",
    "            print(response)\n",
    "            failed += 1\n",
    "\n",
    "\n",
    "# writing master dataframe to csv, indicating now timestamp to keep from overwritting accidentally\n",
    "master_df.to_csv(f'../Resources/Master_Datasets/master_dataset_{int(now)}.csv', index=False)\n",
    "\n",
    "\n",
    "# terminal print out of script performance\n",
    "print(f'''\n",
    "DONE\n",
    "------------------\n",
    "Query Summary\n",
    "Success: {success} \n",
    "Failed: {failed}\n",
    "Total: {record + 1}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "!Query Initiated!\n",
      "-----------------\n",
      "\n",
      "Record 1 out of 164 processed. XOM : SUCCESS(5034 rows)\n",
      "Record 2 out of 164 processed. BRK-A : SUCCESS(5034 rows)\n",
      "Record 3 out of 164 processed. T : SUCCESS(5034 rows)\n",
      "Record 4 out of 164 processed. C : SUCCESS(5034 rows)\n",
      "Record 5 out of 164 processed. MSFT : SUCCESS(5034 rows)\n",
      "Record 6 out of 164 processed. WFC : SUCCESS(5034 rows)\n",
      "Record 7 out of 164 processed. GE : SUCCESS(5034 rows)\n",
      "Record 8 out of 164 processed. F : SUCCESS(5034 rows)\n",
      "Record 9 out of 164 processed. PFE : SUCCESS(5034 rows)\n",
      "Record 10 out of 164 processed. INTC : SUCCESS(5034 rows)\n",
      "Record 11 out of 164 processed. JNJ : SUCCESS(5034 rows)\n",
      "Record 12 out of 164 processed. COP : SUCCESS(5034 rows)\n",
      "Record 13 out of 164 processed. PG : SUCCESS(5034 rows)\n",
      "Record 14 out of 164 processed. MO : SUCCESS(5034 rows)\n",
      "Record 15 out of 164 processed. MRK : SUCCESS(5034 rows)\n",
      "Record 16 out of 164 processed. PEP : SUCCESS(5034 rows)\n",
      "Record 17 out of 164 processed. UNH : SUCCESS(5034 rows)\n",
      "Record 18 out of 164 processed. KO : SUCCESS(5034 rows)\n",
      "Record 19 out of 164 processed. HD : SUCCESS(5034 rows)\n",
      "Record 20 out of 164 processed. UNP : SUCCESS(5034 rows)\n",
      "Record 21 out of 164 processed. BMY : SUCCESS(5034 rows)\n",
      "Record 22 out of 164 processed. DAL : SUCCESS(3183 rows)\n",
      "Record 23 out of 164 processed. BA : SUCCESS(5034 rows)\n",
      "Record 24 out of 164 processed. GM : SUCCESS(2288 rows)\n",
      "Record 25 out of 164 processed. HPE : SUCCESS(1052 rows)\n",
      "Record 26 out of 164 processed. MS : SUCCESS(5034 rows)\n",
      "Record 27 out of 164 processed. OC : SUCCESS(3307 rows)\n",
      "Record 28 out of 164 processed. DD : SUCCESS(142 rows)\n",
      "Record 29 out of 164 processed. DOW : SUCCESS(193 rows)\n",
      "Record 30 out of 164 processed. UTX : SUCCESS(5034 rows)\n",
      "Record 31 out of 164 processed. USB : SUCCESS(5034 rows)\n",
      "Record 32 out of 164 processed. MET : SUCCESS(4960 rows)\n",
      "Record 33 out of 164 processed. AXP : SUCCESS(5034 rows)\n",
      "Record 34 out of 164 processed. OXY : SUCCESS(5034 rows)\n",
      "Record 35 out of 164 processed. TWX : SUCCESS(4652 rows)\n",
      "Record 36 out of 164 processed. CAT : SUCCESS(5034 rows)\n",
      "Record 37 out of 164 processed. ABT : SUCCESS(5034 rows)\n",
      "Record 38 out of 164 processed. TXN : SUCCESS(5034 rows)\n",
      "Record 39 out of 164 processed. CSX : SUCCESS(5034 rows)\n",
      "Record 40 out of 164 processed. VLO : SUCCESS(5034 rows)\n",
      "Record 41 out of 164 processed. NSC : SUCCESS(5034 rows)\n",
      "Record 42 out of 164 processed. MMM : SUCCESS(5034 rows)\n",
      "Record 43 out of 164 processed. LMT : SUCCESS(5034 rows)\n",
      "Record 44 out of 164 processed. GLW : SUCCESS(5034 rows)\n",
      "Record 45 out of 164 processed. MRO : SUCCESS(5034 rows)\n",
      "Record 46 out of 164 processed. MCK : SUCCESS(5034 rows)\n",
      "Record 47 out of 164 processed. LLY : SUCCESS(5034 rows)\n",
      "Record 48 out of 164 processed. BAX : SUCCESS(5034 rows)\n",
      "Record 49 out of 164 processed. FDX : SUCCESS(5034 rows)\n",
      "Record 50 out of 164 processed. L : SUCCESS(5034 rows)\n",
      "Record 51 out of 164 processed. NKE : SUCCESS(5034 rows)\n",
      "Record 52 out of 164 processed. EXC : SUCCESS(5034 rows)\n",
      "Record 53 out of 164 processed. DE : SUCCESS(5034 rows)\n",
      "Record 54 out of 164 processed. HAL : SUCCESS(5034 rows)\n",
      "Record 55 out of 164 processed. LUV : SUCCESS(5034 rows)\n",
      "Record 56 out of 164 processed. AMAT : SUCCESS(5034 rows)\n",
      "Record 57 out of 164 processed. TGT : SUCCESS(5034 rows)\n",
      "Record 58 out of 164 processed. DHR : SUCCESS(5034 rows)\n",
      "Record 59 out of 164 processed. GD : SUCCESS(5034 rows)\n",
      "Record 60 out of 164 processed. PPG : SUCCESS(5034 rows)\n",
      "Record 61 out of 164 processed. NOC : SUCCESS(5034 rows)\n",
      "Record 62 out of 164 processed. KR : SUCCESS(5034 rows)\n",
      "Record 63 out of 164 processed. TJX : SUCCESS(5034 rows)\n",
      "Record 64 out of 164 processed. DUK : SUCCESS(5034 rows)\n",
      "Record 65 out of 164 processed. TSN : SUCCESS(5034 rows)\n",
      "Record 66 out of 164 processed. CBS : SUCCESS(3524 rows)\n",
      "Record 67 out of 164 processed. ITW : SUCCESS(5034 rows)\n",
      "Record 68 out of 164 processed. RTN : SUCCESS(5034 rows)\n",
      "Record 69 out of 164 processed. SEE : SUCCESS(5034 rows)\n",
      "Record 70 out of 164 processed. STI : SUCCESS(5024 rows)\n",
      "Record 71 out of 164 processed. MON : SUCCESS(4437 rows)\n",
      "Record 72 out of 164 processed. EMR : SUCCESS(5034 rows)\n",
      "Record 73 out of 164 processed. CI : SUCCESS(5034 rows)\n",
      "Record 74 out of 164 processed. PGR : SUCCESS(5034 rows)\n",
      "Record 75 out of 164 processed. AA : SUCCESS(790 rows)\n",
      "Record 76 out of 164 processed. MMC : SUCCESS(5034 rows)\n",
      "Record 77 out of 164 processed. CL : SUCCESS(5034 rows)\n",
      "Record 78 out of 164 processed. GT : SUCCESS(5034 rows)\n",
      "Record 79 out of 164 processed. SO : SUCCESS(5034 rows)\n",
      "Record 80 out of 164 processed. HUM : SUCCESS(5034 rows)\n",
      "Record 81 out of 164 processed. BHI : SUCCESS(4413 rows)\n",
      "Record 82 out of 164 processed. VIAB : SUCCESS(3524 rows)\n",
      "Record 83 out of 164 processed. PUSH : SUCCESS(2399 rows)\n",
      "Record 84 out of 164 processed. NUE : SUCCESS(5034 rows)\n",
      "Record 85 out of 164 processed. KMB : SUCCESS(5034 rows)\n",
      "Record 86 out of 164 processed. ADM : SUCCESS(5034 rows)\n",
      "Record 87 out of 164 processed. TXT : SUCCESS(5034 rows)\n",
      "Record 88 out of 164 processed. PCAR : SUCCESS(5034 rows)\n",
      "Record 89 out of 164 processed. WMB : SUCCESS(5034 rows)\n",
      "Record 90 out of 164 processed. IP : SUCCESS(5034 rows)\n",
      "Record 91 out of 164 processed. CMI : SUCCESS(5034 rows)\n",
      "Record 92 out of 164 processed. GIS : SUCCESS(5034 rows)\n",
      "Record 93 out of 164 processed. nan : SUCCESS(5034 rows)\n",
      "Record 94 out of 164 processed. RAD : SUCCESS(5034 rows)\n",
      "Record 95 out of 164 processed. LNC : SUCCESS(5034 rows)\n",
      "Record 96 out of 164 processed. AEP : SUCCESS(5034 rows)\n",
      "Record 97 out of 164 processed. ASH : SUCCESS(5034 rows)\n",
      "Record 98 out of 164 processed. WM : SUCCESS(5034 rows)\n",
      "Record 99 out of 164 processed. CAH : SUCCESS(5034 rows)\n",
      "Record 100 out of 164 processed. PPL : SUCCESS(5034 rows)\n",
      "Record 101 out of 164 processed. FDC : SUCCESS(957 rows)\n",
      "Record 102 out of 164 processed. nan : SUCCESS(5034 rows)\n",
      "Record 103 out of 164 processed. NWE : SUCCESS(3017 rows)\n",
      "Record 104 out of 164 processed. WY : SUCCESS(5034 rows)\n",
      "Record 105 out of 164 processed. K : SUCCESS(5034 rows)\n",
      "Record 106 out of 164 processed. CNP : SUCCESS(5034 rows)\n",
      "Record 107 out of 164 processed. SHW : SUCCESS(5034 rows)\n",
      "Record 108 out of 164 processed. PX : SUCCESS(4747 rows)\n",
      "Record 109 out of 164 processed. NAV : SUCCESS(5034 rows)\n",
      "Record 110 out of 164 processed. GCI : SUCCESS(1482 rows)\n",
      "Record 111 out of 164 processed. PEG : SUCCESS(5034 rows)\n",
      "Record 112 out of 164 processed. ABC : SUCCESS(5034 rows)\n",
      "Record 113 out of 164 processed. JCI : SUCCESS(5034 rows)\n",
      "Record 114 out of 164 processed. EIX : SUCCESS(5034 rows)\n",
      "Record 115 out of 164 processed. ED : SUCCESS(5034 rows)\n",
      "Record 116 out of 164 processed. ROK : SUCCESS(5034 rows)\n",
      "Record 117 out of 164 processed. BBY : SUCCESS(5034 rows)\n",
      "Record 118 out of 164 processed. XRX : SUCCESS(5034 rows)\n",
      "Record 119 out of 164 processed. SYY : SUCCESS(5034 rows)\n",
      "Record 120 out of 164 processed. EMN : SUCCESS(5034 rows)\n",
      "Record 121 out of 164 processed. ETR : SUCCESS(5034 rows)\n",
      "Record 122 out of 164 processed. OI : SUCCESS(5034 rows)\n",
      "Record 123 out of 164 processed. BDX : SUCCESS(5034 rows)\n",
      "Record 124 out of 164 processed. LEA : SUCCESS(2547 rows)\n",
      "Record 125 out of 164 processed. GPS : SUCCESS(5034 rows)\n",
      "Record 126 out of 164 processed. nan : SUCCESS(5034 rows)\n",
      "Record 127 out of 164 processed. VFF : SUCCESS(2453 rows)\n",
      "Record 128 out of 164 processed. CPB : SUCCESS(5034 rows)\n",
      "Record 129 out of 164 processed. JCP : SUCCESS(5034 rows)\n",
      "Record 130 out of 164 processed. THC : SUCCESS(5034 rows)\n",
      "Record 131 out of 164 processed. DTE : SUCCESS(5034 rows)\n",
      "Record 132 out of 164 processed. CLX : SUCCESS(5034 rows)\n",
      "Record 133 out of 164 processed. MHFI : FAILED\n",
      "Record 134 out of 164 processed. nan : SUCCESS(5034 rows)\n",
      "Record 135 out of 164 processed. HRL : SUCCESS(5034 rows)\n",
      "Record 136 out of 164 processed. DOV : SUCCESS(5034 rows)\n",
      "Record 137 out of 164 processed. CAG : SUCCESS(5034 rows)\n",
      "Record 138 out of 164 processed. MAS : SUCCESS(5034 rows)\n",
      "Record 139 out of 164 processed. MAT : SUCCESS(5034 rows)\n",
      "Record 140 out of 164 processed. WHR : SUCCESS(5034 rows)\n",
      "Record 141 out of 164 processed. AVP : SUCCESS(5034 rows)\n",
      "Record 142 out of 164 processed. DF : SUCCESS(5034 rows)\n",
      "Record 143 out of 164 processed. GPC : SUCCESS(5034 rows)\n",
      "Record 144 out of 164 processed. GWW : SUCCESS(5034 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 145 out of 164 processed. R : SUCCESS(5034 rows)\n",
      "Record 146 out of 164 processed. nan : SUCCESS(5034 rows)\n",
      "Record 147 out of 164 processed. JWN : SUCCESS(5034 rows)\n",
      "Record 148 out of 164 processed. ARW : SUCCESS(5034 rows)\n",
      "Record 149 out of 164 processed. AVT : SUCCESS(5034 rows)\n",
      "Record 150 out of 164 processed. FL : SUCCESS(5034 rows)\n",
      "Record 151 out of 164 processed. CMS : SUCCESS(5034 rows)\n",
      "Record 152 out of 164 processed. SVU : SUCCESS(4776 rows)\n",
      "Record 153 out of 164 processed. PBI : SUCCESS(5034 rows)\n",
      "Record 154 out of 164 processed. CCK : SUCCESS(5034 rows)\n",
      "Record 155 out of 164 processed. NCR : SUCCESS(5034 rows)\n",
      "Record 156 out of 164 processed. ODP : SUCCESS(5034 rows)\n",
      "Record 157 out of 164 processed. NWL : SUCCESS(5034 rows)\n",
      "Record 158 out of 164 processed. BLL : SUCCESS(5034 rows)\n",
      "Record 159 out of 164 processed. AVY : SUCCESS(5034 rows)\n",
      "Record 160 out of 164 processed. OMX : SUCCESS(1726 rows)\n",
      "Record 161 out of 164 processed. RRD : SUCCESS(5034 rows)\n",
      "Record 162 out of 164 processed. TECD : SUCCESS(5034 rows)\n",
      "Record 163 out of 164 processed. nan : SUCCESS(5034 rows)\n",
      "Record 164 out of 164 processed. OMI : SUCCESS(5034 rows)\n",
      "\n",
      "DONE\n",
      "------------------\n",
      "Query Summary\n",
      "Success: 163 \n",
      "Failed: 1\n",
      "Total: 164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing dependencies\n",
    "import time\n",
    "import pandas as pd\n",
    "from config import api_key_av\n",
    "import requests\n",
    "\n",
    "\n",
    "# reading in query_list for required tickers\n",
    "query_list = pd.read_csv('../Resources/Query_List.csv')\n",
    "\n",
    "tickers = query_list['ticker'].tolist()\n",
    "# ['ARNC', 'MSFT', 'KO', 'ODP', 'OMX', 'GE']\n",
    "\n",
    "# terminal print out of script performance\n",
    "print(f'''\n",
    "!Query Initiated!\n",
    "-----------------\n",
    "''')\n",
    "\n",
    "# creating limit response note from AV\n",
    "bad_call = 'Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and 500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency.'\n",
    "\n",
    "\n",
    "# creating loop counters & summary stat counters\n",
    "success = 0 #success API call counter\n",
    "failed = 0 #failed API call counter\n",
    "\n",
    "# creating master dataframe (to append to)\n",
    "master_df = pd.DataFrame(columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker'])\n",
    "\n",
    "# primary loop for ticker call list to API\n",
    "for record, ticker in enumerate(tickers):\n",
    "    \n",
    "    # setting API call parameters (ticker)\n",
    "    params = {\n",
    "        'function' : 'TIME_SERIES_DAILY',\n",
    "        'symbol' : ticker,\n",
    "        'outputsize' : 'full',\n",
    "        'datatype' : 'json',\n",
    "        'apikey' : api_key_av\n",
    "    }\n",
    "    \n",
    "    # base API call URL\n",
    "    url = 'https://www.alphavantage.co/query?'\n",
    "\n",
    "\n",
    "    # trying API call and skipping if failed for any reason\n",
    "    try:\n",
    "        \n",
    "        # making API call and storing data into variable\n",
    "        response = requests.get(url, params).json()\n",
    "        \n",
    "        try:\n",
    "            if response['Note'] == bad_call:\n",
    "                while response['Note'] == bad_call:\n",
    "                    response = requests.get(url, params).json()\n",
    "\n",
    "        except:\n",
    "\n",
    "            # THE MEAT AND POTATOS\n",
    "            # creating main ticker dataframe\n",
    "            ticker_df = pd.DataFrame(response['Time Series (Daily)']).transpose().reset_index()\n",
    "\n",
    "            # renaming columns to better indicators\n",
    "            ticker_df = ticker_df.rename(columns={\n",
    "                'index':'Date',\n",
    "                '1. open':'Open',\n",
    "                '2. high':'High',\n",
    "                '3. low':'Low',\n",
    "                '4. close':'Close',\n",
    "                '5. volume':'Volume'\n",
    "            })\n",
    "\n",
    "            # pulling ticker symbol for confirmation purposes from API\n",
    "            ticker_df['Ticker'] = response['Meta Data']['2. Symbol']\n",
    "\n",
    "\n",
    "            # appending items to master dataframe\n",
    "            master_df = master_df.append(ticker_df)\n",
    "\n",
    "            row_count = ticker_df['Date'].count()\n",
    "\n",
    "            print(f'Record {record + 1} out of {len(tickers)} processed. {ticker} : SUCCESS({row_count} rows)')\n",
    "\n",
    "            success += 1\n",
    "\n",
    "\n",
    "    # handeling failed API calls\n",
    "    except:\n",
    "        print(f'Record {record + 1} out of {len(tickers)} processed. {ticker} : FAILED')\n",
    "\n",
    "        failed += 1\n",
    "\n",
    "\n",
    "# writing master dataframe to csv, indicating now timestamp to keep from overwritting accidentally\n",
    "master_df.to_csv(f'../Resources/Master_Datasets/master_dataset_{int(now)}.csv', index=False)\n",
    "\n",
    "\n",
    "# terminal print out of script performance\n",
    "print(f'''\n",
    "DONE\n",
    "------------------\n",
    "Query Summary\n",
    "Success: {success} \n",
    "Failed: {failed}\n",
    "Total: {record + 1}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>69.86</td>\n",
       "      <td>70.2267</td>\n",
       "      <td>69.39</td>\n",
       "      <td>69.94</td>\n",
       "      <td>35091987</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>69.99</td>\n",
       "      <td>70.0500</td>\n",
       "      <td>69.24</td>\n",
       "      <td>69.39</td>\n",
       "      <td>13273228</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-18</td>\n",
       "      <td>69.63</td>\n",
       "      <td>70.2900</td>\n",
       "      <td>69.28</td>\n",
       "      <td>69.87</td>\n",
       "      <td>13652100</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-17</td>\n",
       "      <td>69.98</td>\n",
       "      <td>70.3800</td>\n",
       "      <td>69.31</td>\n",
       "      <td>69.68</td>\n",
       "      <td>14450050</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>69.70</td>\n",
       "      <td>70.2500</td>\n",
       "      <td>69.70</td>\n",
       "      <td>70.00</td>\n",
       "      <td>15208665</td>\n",
       "      <td>XOM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770348</th>\n",
       "      <td>1999-12-27</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.7500</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.50</td>\n",
       "      <td>62800</td>\n",
       "      <td>OMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770349</th>\n",
       "      <td>1999-12-23</td>\n",
       "      <td>8.62</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>8.50</td>\n",
       "      <td>8.56</td>\n",
       "      <td>45267</td>\n",
       "      <td>OMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770350</th>\n",
       "      <td>1999-12-22</td>\n",
       "      <td>8.13</td>\n",
       "      <td>8.5000</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.50</td>\n",
       "      <td>259400</td>\n",
       "      <td>OMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770351</th>\n",
       "      <td>1999-12-21</td>\n",
       "      <td>8.37</td>\n",
       "      <td>8.3700</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.31</td>\n",
       "      <td>102400</td>\n",
       "      <td>OMI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770352</th>\n",
       "      <td>1999-12-20</td>\n",
       "      <td>8.19</td>\n",
       "      <td>8.3700</td>\n",
       "      <td>8.06</td>\n",
       "      <td>8.37</td>\n",
       "      <td>195067</td>\n",
       "      <td>OMI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770353 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date   Open     High    Low  Close    Volume Ticker\n",
       "0       2019-12-20  69.86  70.2267  69.39  69.94  35091987    XOM\n",
       "1       2019-12-19  69.99  70.0500  69.24  69.39  13273228    XOM\n",
       "2       2019-12-18  69.63  70.2900  69.28  69.87  13652100    XOM\n",
       "3       2019-12-17  69.98  70.3800  69.31  69.68  14450050    XOM\n",
       "4       2019-12-16  69.70  70.2500  69.70  70.00  15208665    XOM\n",
       "...            ...    ...      ...    ...    ...       ...    ...\n",
       "770348  1999-12-27   8.44   8.7500   8.25   8.50     62800    OMI\n",
       "770349  1999-12-23   8.62   9.0000   8.50   8.56     45267    OMI\n",
       "770350  1999-12-22   8.13   8.5000   8.06   8.50    259400    OMI\n",
       "770351  1999-12-21   8.37   8.3700   8.06   8.31    102400    OMI\n",
       "770352  1999-12-20   8.19   8.3700   8.06   8.37    195067    OMI\n",
       "\n",
       "[770353 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviewing last master_dataset output\n",
    "lmds_df = pd.read_csv(f'../Resources/Master_Datasets/master_dataset_{int(now)}.csv')\n",
    "lmds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor making it fast:\\n\\n\\nif response['Note'] = bad_call:\\n    while response['Note'] = bad_call:\\n        response = requests.get(url, params).json()\\n\\nbad_call = 'Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and 500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency.'\\n\\n\\n\\nalso remove the wait loops\\n\\nresponse:\\n{'Note': 'Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and \\n500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency.'}\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "response:\n",
    "{'Note': 'Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and \n",
    "500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency.'}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "recommendation / hybrid:\n",
    "\n",
    "1open working csv to df to append to\n",
    "2spam API until get bad_call response\n",
    "3save off data to dataframe to csv\n",
    "4wait using system time until next minute i.e. ((time.time)/60).isinteger\n",
    "\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
